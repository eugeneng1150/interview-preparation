# data-science-interviews
Questions/ answers/ materials used to study and prepare for data science interviews <br>
Major credits to: [this repo](https://github.com/alexeygrigorev/data-science-interviews)

# Reading Materials:

### **Supervised Learning Algorithms:**
1. **Linear Regression**
   - https://www.analyticsvidhya.com/blog/2021/06/linear-regression-in-machine-learning/
   - Used for regression tasks to predict a continuous target variable.
2. **Logistic Regression**
   - https://www.analyticsvidhya.com/blog/2021/10/building-an-end-to-end-logistic-regression-model/
   - Used for binary classification problems.
3. **Decision Trees**
   - https://www.analyticsvidhya.com/blog/2021/08/decision-tree-algorithm/
   - A tree-based model for both classification and regression tasks.
4. **Random Forest**
   - https://www.analyticsvidhya.com/blog/2021/06/understanding-random-forest/
   - An ensemble method based on multiple decision trees.
5. **Support Vector Machines (SVM)**
   - https://www.analyticsvidhya.com/blog/2021/10/support-vector-machinessvm-a-complete-guide-for-beginners/
   - Used for classification tasks by finding the optimal hyperplane.
6. **K-Nearest Neighbors (KNN)**
   - https://www.analyticsvidhya.com/blog/2018/03/introduction-k-neighbours-algorithm-clustering/
   - A simple classification algorithm that assigns a class based on the majority class of nearest neighbors.
7. **Naive Bayes**
   - https://www.analyticsvidhya.com/blog/2017/09/naive-bayes-explained/
   - A probabilistic classifier based on Bayes' theorem with strong independence assumptions.
8. **Gradient Boosting Machines (GBM)**
   - https://www.analyticsvidhya.com/blog/2021/09/gradient-boosting-algorithm-a-complete-guide-for-beginners/
   - An ensemble method that builds models sequentially to reduce errors.
9. **AdaBoost**
   - https://www.analyticsvidhya.com/blog/2021/09/adaboost-algorithm-a-complete-guide-for-beginners/
   - https://www.analyticsvidhya.com/blog/2021/03/introduction-to-adaboost-algorithm-with-python/
   - A boosting method that combines weak learners to form a strong classifier.
10. **XGBoost**
    - https://www.analyticsvidhya.com/blog/2018/09/an-end-to-end-guide-to-understand-the-math-behind-xgboost/
    - https://www.analyticsvidhya.com/blog/2018/06/comprehensive-guide-for-ensemble-models/
    - A popular gradient boosting framework optimized for performance.


### **Unsupervised Learning Algorithms:**
1. **K-Means Clustering**
   - https://www.analyticsvidhya.com/blog/2019/08/comprehensive-guide-k-means-clustering/
   - A popular clustering algorithm that partitions data into K clusters.
2. **Hierarchical Clustering**
   - https://www.analyticsvidhya.com/blog/2022/11/hierarchical-clustering-in-machine-learning/
   - https://www.analyticsvidhya.com/blog/2021/06/single-link-hierarchical-clustering-clearly-explained/
   - A clustering technique that builds a hierarchy of clusters.
3. **DBSCAN (Density-Based Spatial Clustering of Applications with Noise)**
   - https://www.analyticsvidhya.com/blog/2021/06/understand-the-dbscan-clustering-algorithm/
   - https://www.analyticsvidhya.com/blog/2020/09/how-dbscan-clustering-works/
   - Clustering algorithm that groups together closely packed points and marks outliers.
4. **Principal Component Analysis (PCA)**
   - https://www.analyticsvidhya.com/blog/2016/03/pca-practical-guide-principal-component-analysis-python/
   - https://towardsdatascience.com/the-mathematics-behind-principal-component-analysis-fff2d7f4b643
   - A dimensionality reduction technique used to project data onto fewer dimensions.
5. **t-SNE (t-distributed Stochastic Neighbor Embedding)**
   - https://medium.com/@sachinsoni600517/mastering-t-sne-t-distributed-stochastic-neighbor-embedding-0e365ee898ea
   - A non-linear dimensionality reduction method for visualizing high-dimensional data.


### **Reinforcement Learning Algorithms:**
1. **Q-Learning**
   - A model-free reinforcement learning algorithm based on learning a Q-value function.
2. **Deep Q-Networks (DQN)**
   - A combination of Q-learning and deep neural networks.
3. **Policy Gradient Methods**
   - Learn policies directly instead of learning a value function.
4. **Proximal Policy Optimization (PPO)**
   - A modern, stable policy optimization method used in reinforcement learning.
5. **SARSA (State-Action-Reward-State-Action)**
   - A reinforcement learning algorithm that updates policies based on current actions.

### **Neural Networks and Deep Learning Algorithms:**
1. **Artificial Neural Networks (ANN)**
   - The basic neural network model used for various tasks.
2. **Convolutional Neural Networks (CNN)**
   - Primarily used for image recognition tasks.
3. **Recurrent Neural Networks (RNN)**
   - Used for sequential data tasks like time series or natural language processing.
4. **Long Short-Term Memory Networks (LSTM)**
   - A type of RNN capable of learning long-term dependencies.
5. **Transformer Networks**
   - A deep learning architecture primarily used in NLP tasks (e.g., BERT, GPT).
6. **Generative Adversarial Networks (GANs)**
   - A framework involving two neural networks to generate new data.

### **Ensemble Learning Algorithms:**
1. **Bagging**
   - Combines the predictions of several base models (e.g., Random Forest).
2. **Boosting**
   - Sequentially builds models that correct the errors of previous models (e.g., XGBoost, AdaBoost).
3. **Stacking**
   - Combines multiple models by training a meta-model on their predictions.

